{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Take care of yourself! =)\n\nOn this kernel, I'll try to find the best features with two different methodologies: \n1. **Intuition** from correlation data.\n2. **SelectKBest** algorithm.\n\nWhich one is better? What will the difference between performances be?"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# packages \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import ExtraTreesRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading file\ndf = pd.read_excel(r'/kaggle/input/covid19/dataset.xlsx')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initial exploring data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Patient ID isn't necessary\ndf = df.drop(columns='Patient ID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Are there blank?\nnp.where(df.applymap(lambda x: x == ''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Searching for NaNs\ndf.info(verbose=True, null_counts=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's apply a function to check nulls "},{"metadata":{"trusted":true},"cell_type":"code","source":"def intitial_eda_checks(df):\n    '''\n    Thanks to: https://github.com/FredaXin/blog_posts/blob/master/creating_functions_for_EDA.md\n    Takes df\n    Checks nulls\n    '''\n    if df.isnull().sum().sum() > 0:\n        mask_total = df.isnull().sum().sort_values(ascending=False) \n        total = mask_total[mask_total > 0]\n\n        mask_percent = df.isnull().mean().sort_values(ascending=False) \n        percent = mask_percent[mask_percent > 0] \n\n        missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    \n        print(f'Total and Percentage of NaN:\\n {missing_data}')\n    else: \n        print('No NaN found.')\n        \nintitial_eda_checks(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now another function to drop columns with 90% of NaNs or more."},{"metadata":{"trusted":true},"cell_type":"code","source":"def view_columns_w_many_nans(df, missing_percent):\n    '''\n    Thanks to: https://github.com/FredaXin/blog_posts/blob/master/creating_functions_for_EDA.md\n    Checks which columns have over specified percentage of missing values\n    Takes df, missing percentage\n    Returns columns as a list\n    '''\n    mask_percent = df.isnull().mean()\n    series = mask_percent[mask_percent > missing_percent]\n    columns = series.index.to_list()\n    print(columns) \n    return columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cols = view_columns_w_many_nans(df, .9)\ndf0 = df.drop(columns=list_of_cols)\n#Here they are: ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the dataset for task 1\ndf1 = df0.drop(columns=['Patient addmited to regular ward (1=yes, 0=no)', \n                        'Patient addmited to semi-intensive unit (1=yes, 0=no)',\n                       'Patient addmited to intensive care unit (1=yes, 0=no)'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing text data to numbers - negative: 0, positive: 1.\ndf1['SARS-Cov-2 exam result'] = df1['SARS-Cov-2 exam result'].replace({'negative': 0, 'positive': 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get dummies because machine learning algorithms prefers numbers!\ndf1_dummy = pd.get_dummies(df1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What features to choose? Let's go to the two methods."},{"metadata":{},"cell_type":"markdown","source":"# **1. Intuition from correlation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation \ncorr_matrix_df1 = df1_dummy.corr()\n\ncorr_matrix_df1['SARS-Cov-2 exam result'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, now it starts the intuition part.\n\nI chose the following features: \n\n***Monocytes, Red blood Cells, Mean platelet volume, Hemoglobin, Hematocrit, Basophils, Eosinophils, \nPlatelets and Leukocytes.***\n\nBut why?\n\n* As we know, it's necessary to choose the the furthest values from zero. \n* Features seems to be blood components. So I eliminated *Rhinovirus/Enterovirus_detected* column to try set a pattern. \n* Finally, [there are reports](http:www.dw.com/pt-br/como-funciona-o-teste-rápido-de-coronavírus/a-52626671) that blood tests have been used to perform rapid coronavirus tests:\n\n> \"Realizam-se pesquisas em todo o mundo, e já estão disponíveis as primeiras abordagens promissoras para um teste rápido simplificado, semelhante ao teste da glicose no sangue.\n> Por exemplo, com o exame de uma gota de sangue, em apenas 15 minutos, o teste rápido apresentado pela Comissão Nacional de Saúde da China é capaz de detectar imunoglobulinas, os anticorpos que o corpo humano forma inicialmente quando ocorre uma nova infecção.\"\n\nOf course, I'm not assuming that this is an absolute truth. They're just clues to choose the features.\n\n--\nNotes:\n\nI tested the models with *Rhinovirus/Enterovirus_detected* and the others blood components out of the selected range, but on the first case it was indifferent and on the second case the algorithm performed worst.\n\nRhinovirus/Enterovirus detection isn't necessarily useless. For instance, in view of the difficulty in performing coronavirus exams and depending on the resources, I came up with the following hypothesis:\n\nSince among the exams, the Rhinovirus/Enterovirus detection seems to be one that most correlates with exam results for the novel coronavirus, if a patient have certain symptoms, history, other specific informations etc and **Rhinovirus/Enterovirus is not detected**, is there probability of being COVID-19?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# New DataFrame with target and selected features to plot correlation\ndf1_new = df1_dummy[['SARS-Cov-2 exam result','Monocytes', 'Red blood Cells', 'Mean platelet volume ',\n                    'Hemoglobin', 'Hematocrit','Basophils','Eosinophils', 'Platelets', 'Leukocytes']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def heatmap_numeric_w_dependent_variable(df, dependent_variable):\n    '''\n    thanks to: https://github.com/FredaXin/blog_posts/blob/master/creating_functions_for_EDA.md\n    Takes df, a dependant variable as str\n    Returns a heatmap of all independent variables' correlations with dependent variable \n    '''\n    plt.figure(figsize=(8, 10))\n    g = sns.heatmap(df.corr()[[dependent_variable]].sort_values(by=dependent_variable), \n                    annot=True, \n                    cmap='coolwarm', \n                    vmin=-1,\n                    vmax=1) \n    return g","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting correlations with 'SARS-Cov-2 exam result' column\nheatmap_numeric_w_dependent_variable(df1_new, 'SARS-Cov-2 exam result')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining features and target\nX1 = df1_new.drop(['SARS-Cov-2 exam result'], axis=1)\n\ny1 = df1_new['SARS-Cov-2 exam result']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputation of missing values with multivariate imputation algorithm\nimp = IterativeImputer(max_iter=10, random_state=0)\n\nimp.fit(X1)\n\nX1 = imp.transform(X1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling X1\nscaler = MinMaxScaler()\n\nscaler.fit(X1)\n\nX1 = scaler.transform(X1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split\n\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, random_state=33)     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LinearSVC\nclf = LinearSVC(random_state=0, tol=1e-5)\n\nclf.fit(X1_train, y1_train)\n\ny1_pred = clf.predict(X1_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross-validation \nall_accuracies_clf_1 = cross_val_score(estimator=clf, X=X1_train, \n                                 y=y1_train, cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean accuracy and standard deviation\nmean_acc_corrint = all_accuracies_clf_1.mean()*100\nstd_acc_corrint = all_accuracies_clf_1.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's select features with a selector algorithm."},{"metadata":{},"cell_type":"markdown","source":"# **2. *SelectKBest***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining features and target\nX2 = df1_dummy.drop(['SARS-Cov-2 exam result'], axis=1)\n\ny2 = df1_dummy['SARS-Cov-2 exam result']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I'll need this to apply SelectKBest algorithm \nX2_columns = X2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputation of missing values with multivariate imputation algorithm\nimp = IterativeImputer(max_iter=10, random_state=0)\n\nimp.fit(X2)\n\nX2 = imp.transform(X2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling X2\nscaler = MinMaxScaler()\n\nscaler.fit(X2)\n\nX2 = scaler.transform(X2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transforming X and y to DataFrame to apply SelectKbest and return the selected columns\ny2 = pd.DataFrame(data=y2, columns=['SARS-Cov-2 exam result'])\n\nX2 = pd.DataFrame(data=X2, columns=X2_columns) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying\nselector = SelectKBest(chi2, k=5)\nselector.fit(X2, y2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selected columns\n# thanks to: https://stackoverflow.com/questions/46927545/get-feature-names-of-selectkbest-function-python\nX_new = selector.transform(X2)\nprint(X_new.shape)\n\nX2.columns[selector.get_support(indices=True)]\n\nvector_names = list(X2.columns[selector.get_support(indices=True)])\nprint(vector_names)\n\nX2.columns[selector.get_support(indices=True)].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assigning target\ny_new = np.ravel(y2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split\n\nX_new_train, X_new_test, y_new_train, y_new_test = train_test_split(X_new, y_new, \n                                                                    random_state=33)                                                                     \n                                                                   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LinearSVC\nclf = LinearSVC(random_state=0, tol=1e-5)\n\nclf.fit(X_new_train, y_new_train)\n\ny_new_pred = clf.predict(X_new_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross-validation \nall_accuracies_clf_2 = cross_val_score(estimator=clf, X=X_new_train, \n                                 y=y_new_train, cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean accuracy and standard deviation\nmean_acc_selector = all_accuracies_clf_2.mean()*100\nstd_acc_selector = all_accuracies_clf_2.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Resuming the results:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The average accuracy of the first model is', mean_acc_corrint, '%')\nprint('and the standard deviation is', std_acc_corrint,'.')\nprint()\nprint('The average accuracy of the second model is', mean_acc_selector, '%')\nprint('and the standard deviation is', std_acc_selector, '.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we saw above, both methods had good performance. But the first was a little better, proving that our intuition and knowledge of the world can be useful to obtain good results in models of Machine Learning.\n\nFinally, it's always good to remember:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('STAY HOME, IF YOU CAN.')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}